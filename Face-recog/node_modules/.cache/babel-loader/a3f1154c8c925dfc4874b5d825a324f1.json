{"ast":null,"code":"\"use strict\";\n\nvar _regeneratorRuntime = require(\"D:\\\\IMPORTANT\\\\visuallyimp-atmoeye-main\\\\EyeSight-main\\\\eyesight\\\\Face-recog\\\\node_modules\\\\@babel\\\\runtime/regenerator\");\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports[\"default\"] = exports.useSpeechRecognition = void 0;\nvar _react = require(\"react\");\nvar _utils = require(\"./utils\");\nvar _actions = require(\"./actions\");\nvar _reducers = require(\"./reducers\");\nvar _RecognitionManager = _interopRequireDefault(require(\"./RecognitionManager\"));\nvar _isAndroid = _interopRequireDefault(require(\"./isAndroid\"));\nvar _NativeSpeechRecognition = _interopRequireDefault(require(\"./NativeSpeechRecognition\"));\nfunction _interopRequireDefault(obj) {\n  return obj && obj.__esModule ? obj : {\n    \"default\": obj\n  };\n}\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {\n  try {\n    var info = gen[key](arg);\n    var value = info.value;\n  } catch (error) {\n    reject(error);\n    return;\n  }\n  if (info.done) {\n    resolve(value);\n  } else {\n    Promise.resolve(value).then(_next, _throw);\n  }\n}\nfunction _asyncToGenerator(fn) {\n  return function () {\n    var self = this,\n      args = arguments;\n    return new Promise(function (resolve, reject) {\n      var gen = fn.apply(self, args);\n      function _next(value) {\n        asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value);\n      }\n      function _throw(err) {\n        asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err);\n      }\n      _next(undefined);\n    });\n  };\n}\nfunction _toConsumableArray(arr) {\n  return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread();\n}\nfunction _nonIterableSpread() {\n  throw new TypeError(\"Invalid attempt to spread non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\nfunction _iterableToArray(iter) {\n  if (typeof Symbol !== \"undefined\" && Symbol.iterator in Object(iter)) return Array.from(iter);\n}\nfunction _arrayWithoutHoles(arr) {\n  if (Array.isArray(arr)) return _arrayLikeToArray(arr);\n}\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n  return _typeof(obj);\n}\nfunction _slicedToArray(arr, i) {\n  return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest();\n}\nfunction _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n}\nfunction _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n  return arr2;\n}\nfunction _iterableToArrayLimit(arr, i) {\n  if (typeof Symbol === \"undefined\" || !(Symbol.iterator in Object(arr))) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n  var _e = undefined;\n  try {\n    for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n  return _arr;\n}\nfunction _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\nvar _browserSupportsSpeechRecognition = !!_NativeSpeechRecognition[\"default\"];\nvar _browserSupportsContinuousListening = _browserSupportsSpeechRecognition && !(0, _isAndroid[\"default\"])();\nvar recognitionManager;\nvar useSpeechRecognition = function useSpeechRecognition() {\n  var _ref = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {},\n    _ref$transcribing = _ref.transcribing,\n    transcribing = _ref$transcribing === void 0 ? true : _ref$transcribing,\n    _ref$clearTranscriptO = _ref.clearTranscriptOnListen,\n    clearTranscriptOnListen = _ref$clearTranscriptO === void 0 ? true : _ref$clearTranscriptO,\n    _ref$commands = _ref.commands,\n    commands = _ref$commands === void 0 ? [] : _ref$commands;\n  var _useState = (0, _react.useState)(SpeechRecognition.getRecognitionManager()),\n    _useState2 = _slicedToArray(_useState, 1),\n    recognitionManager = _useState2[0];\n  var _useState3 = (0, _react.useState)(_browserSupportsSpeechRecognition),\n    _useState4 = _slicedToArray(_useState3, 2),\n    browserSupportsSpeechRecognition = _useState4[0],\n    setBrowserSupportsSpeechRecognition = _useState4[1];\n  var _useState5 = (0, _react.useState)(_browserSupportsContinuousListening),\n    _useState6 = _slicedToArray(_useState5, 2),\n    browserSupportsContinuousListening = _useState6[0],\n    setBrowserSupportsContinuousListening = _useState6[1];\n  var _useReducer = (0, _react.useReducer)(_reducers.transcriptReducer, {\n      interimTranscript: recognitionManager.interimTranscript,\n      finalTranscript: ''\n    }),\n    _useReducer2 = _slicedToArray(_useReducer, 2),\n    _useReducer2$ = _useReducer2[0],\n    interimTranscript = _useReducer2$.interimTranscript,\n    finalTranscript = _useReducer2$.finalTranscript,\n    dispatch = _useReducer2[1];\n  var _useState7 = (0, _react.useState)(recognitionManager.listening),\n    _useState8 = _slicedToArray(_useState7, 2),\n    listening = _useState8[0],\n    setListening = _useState8[1];\n  var _useState9 = (0, _react.useState)(recognitionManager.isMicrophoneAvailable),\n    _useState10 = _slicedToArray(_useState9, 2),\n    isMicrophoneAvailable = _useState10[0],\n    setMicrophoneAvailable = _useState10[1];\n  var commandsRef = (0, _react.useRef)(commands);\n  commandsRef.current = commands;\n  var dispatchClearTranscript = function dispatchClearTranscript() {\n    dispatch((0, _actions.clearTranscript)());\n  };\n  var resetTranscript = (0, _react.useCallback)(function () {\n    recognitionManager.resetTranscript();\n    dispatchClearTranscript();\n  }, [recognitionManager]);\n  var testFuzzyMatch = function testFuzzyMatch(command, input, fuzzyMatchingThreshold) {\n    var commandToString = _typeof(command) === 'object' ? command.toString() : command;\n    var commandWithoutSpecials = commandToString.replace(/[&/\\\\#,+()!$~%.'\":*?<>{}]/g, '').replace(/  +/g, ' ').trim();\n    var howSimilar = (0, _utils.compareTwoStringsUsingDiceCoefficient)(commandWithoutSpecials, input);\n    if (howSimilar >= fuzzyMatchingThreshold) {\n      return {\n        command: command,\n        commandWithoutSpecials: commandWithoutSpecials,\n        howSimilar: howSimilar,\n        isFuzzyMatch: true\n      };\n    }\n    return null;\n  };\n  var testMatch = function testMatch(command, input) {\n    var pattern = (0, _utils.commandToRegExp)(command);\n    var result = pattern.exec(input);\n    if (result) {\n      return {\n        command: command,\n        parameters: result.slice(1)\n      };\n    }\n    return null;\n  };\n  var matchCommands = (0, _react.useCallback)(function (newInterimTranscript, newFinalTranscript) {\n    commandsRef.current.forEach(function (_ref2) {\n      var command = _ref2.command,\n        callback = _ref2.callback,\n        _ref2$matchInterim = _ref2.matchInterim,\n        matchInterim = _ref2$matchInterim === void 0 ? false : _ref2$matchInterim,\n        _ref2$isFuzzyMatch = _ref2.isFuzzyMatch,\n        isFuzzyMatch = _ref2$isFuzzyMatch === void 0 ? false : _ref2$isFuzzyMatch,\n        _ref2$fuzzyMatchingTh = _ref2.fuzzyMatchingThreshold,\n        fuzzyMatchingThreshold = _ref2$fuzzyMatchingTh === void 0 ? 0.8 : _ref2$fuzzyMatchingTh,\n        _ref2$bestMatchOnly = _ref2.bestMatchOnly,\n        bestMatchOnly = _ref2$bestMatchOnly === void 0 ? false : _ref2$bestMatchOnly;\n      var input = !newFinalTranscript && matchInterim ? newInterimTranscript.trim() : newFinalTranscript.trim();\n      var subcommands = Array.isArray(command) ? command : [command];\n      var results = subcommands.map(function (subcommand) {\n        if (isFuzzyMatch) {\n          return testFuzzyMatch(subcommand, input, fuzzyMatchingThreshold);\n        }\n        return testMatch(subcommand, input);\n      }).filter(function (x) {\n        return x;\n      });\n      if (isFuzzyMatch && bestMatchOnly && results.length >= 2) {\n        results.sort(function (a, b) {\n          return b.howSimilar - a.howSimilar;\n        });\n        var _results$ = results[0],\n          _command = _results$.command,\n          commandWithoutSpecials = _results$.commandWithoutSpecials,\n          howSimilar = _results$.howSimilar;\n        callback(commandWithoutSpecials, input, howSimilar, {\n          command: _command,\n          resetTranscript: resetTranscript\n        });\n      } else {\n        results.forEach(function (result) {\n          if (result.isFuzzyMatch) {\n            var _command2 = result.command,\n              _commandWithoutSpecials = result.commandWithoutSpecials,\n              _howSimilar = result.howSimilar;\n            callback(_commandWithoutSpecials, input, _howSimilar, {\n              command: _command2,\n              resetTranscript: resetTranscript\n            });\n          } else {\n            var _command3 = result.command,\n              parameters = result.parameters;\n            callback.apply(void 0, _toConsumableArray(parameters).concat([{\n              command: _command3,\n              resetTranscript: resetTranscript\n            }]));\n          }\n        });\n      }\n    });\n  }, [resetTranscript]);\n  var handleTranscriptChange = (0, _react.useCallback)(function (newInterimTranscript, newFinalTranscript) {\n    if (transcribing) {\n      dispatch((0, _actions.appendTranscript)(newInterimTranscript, newFinalTranscript));\n    }\n    matchCommands(newInterimTranscript, newFinalTranscript);\n  }, [matchCommands, transcribing]);\n  var handleClearTranscript = (0, _react.useCallback)(function () {\n    if (clearTranscriptOnListen) {\n      dispatchClearTranscript();\n    }\n  }, [clearTranscriptOnListen]);\n  (0, _react.useEffect)(function () {\n    var id = SpeechRecognition.counter;\n    SpeechRecognition.counter += 1;\n    var callbacks = {\n      onListeningChange: setListening,\n      onMicrophoneAvailabilityChange: setMicrophoneAvailable,\n      onTranscriptChange: handleTranscriptChange,\n      onClearTranscript: handleClearTranscript,\n      onBrowserSupportsSpeechRecognitionChange: setBrowserSupportsSpeechRecognition,\n      onBrowserSupportsContinuousListeningChange: setBrowserSupportsContinuousListening\n    };\n    recognitionManager.subscribe(id, callbacks);\n    return function () {\n      recognitionManager.unsubscribe(id);\n    };\n  }, [transcribing, clearTranscriptOnListen, recognitionManager, handleTranscriptChange, handleClearTranscript]);\n  var transcript = (0, _utils.concatTranscripts)(finalTranscript, interimTranscript);\n  return {\n    transcript: transcript,\n    interimTranscript: interimTranscript,\n    finalTranscript: finalTranscript,\n    listening: listening,\n    isMicrophoneAvailable: isMicrophoneAvailable,\n    resetTranscript: resetTranscript,\n    browserSupportsSpeechRecognition: browserSupportsSpeechRecognition,\n    browserSupportsContinuousListening: browserSupportsContinuousListening\n  };\n};\nexports.useSpeechRecognition = useSpeechRecognition;\nvar SpeechRecognition = {\n  counter: 0,\n  applyPolyfill: function applyPolyfill(PolyfillSpeechRecognition) {\n    if (recognitionManager) {\n      recognitionManager.setSpeechRecognition(PolyfillSpeechRecognition);\n    } else {\n      recognitionManager = new _RecognitionManager[\"default\"](PolyfillSpeechRecognition);\n    }\n    var browserSupportsPolyfill = !!PolyfillSpeechRecognition && (0, _utils.browserSupportsPolyfills)();\n    _browserSupportsSpeechRecognition = browserSupportsPolyfill;\n    _browserSupportsContinuousListening = browserSupportsPolyfill;\n  },\n  removePolyfill: function removePolyfill() {\n    if (recognitionManager) {\n      recognitionManager.setSpeechRecognition(_NativeSpeechRecognition[\"default\"]);\n    } else {\n      recognitionManager = new _RecognitionManager[\"default\"](_NativeSpeechRecognition[\"default\"]);\n    }\n    _browserSupportsSpeechRecognition = !!_NativeSpeechRecognition[\"default\"];\n    _browserSupportsContinuousListening = _browserSupportsSpeechRecognition && !(0, _isAndroid[\"default\"])();\n  },\n  getRecognitionManager: function getRecognitionManager() {\n    if (!recognitionManager) {\n      recognitionManager = new _RecognitionManager[\"default\"](_NativeSpeechRecognition[\"default\"]);\n    }\n    return recognitionManager;\n  },\n  getRecognition: function getRecognition() {\n    var recognitionManager = SpeechRecognition.getRecognitionManager();\n    return recognitionManager.getRecognition();\n  },\n  startListening: function () {\n    var _startListening = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n      var _ref3,\n        continuous,\n        language,\n        recognitionManager,\n        _args = arguments;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              _ref3 = _args.length > 0 && _args[0] !== undefined ? _args[0] : {}, continuous = _ref3.continuous, language = _ref3.language;\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context.next = 4;\n              return recognitionManager.startListening({\n                continuous: continuous,\n                language: language\n              });\n            case 4:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }));\n    function startListening() {\n      return _startListening.apply(this, arguments);\n    }\n    return startListening;\n  }(),\n  stopListening: function () {\n    var _stopListening = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n      var recognitionManager;\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context2.next = 3;\n              return recognitionManager.stopListening();\n            case 3:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n    function stopListening() {\n      return _stopListening.apply(this, arguments);\n    }\n    return stopListening;\n  }(),\n  abortListening: function () {\n    var _abortListening = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n      var recognitionManager;\n      return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n        while (1) {\n          switch (_context3.prev = _context3.next) {\n            case 0:\n              recognitionManager = SpeechRecognition.getRecognitionManager();\n              _context3.next = 3;\n              return recognitionManager.abortListening();\n            case 3:\n            case \"end\":\n              return _context3.stop();\n          }\n        }\n      }, _callee3);\n    }));\n    function abortListening() {\n      return _abortListening.apply(this, arguments);\n    }\n    return abortListening;\n  }(),\n  browserSupportsSpeechRecognition: function browserSupportsSpeechRecognition() {\n    return _browserSupportsSpeechRecognition;\n  },\n  browserSupportsContinuousListening: function browserSupportsContinuousListening() {\n    return _browserSupportsContinuousListening;\n  }\n};\nvar _default = SpeechRecognition;\nexports[\"default\"] = _default;","map":null,"metadata":{},"sourceType":"script"}